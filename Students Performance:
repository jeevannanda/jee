#1. Import required libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#2. Read the data
#Assuming your data is in a CSV file named "studentsperformance.csv," you can read it as follows:

df= pd.read_csv('StudentsPerformance.csv')
#3.Check the Dataset summary.
#this code will display a summary of the dataset, including information about the number of non-null values, 
#data types of columns, and memory usage.
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 8 columns):
gender                         1000 non-null object
race/ethnicity                 1000 non-null object
parental level of education    1000 non-null object
lunch                          1000 non-null object
test preparation course        1000 non-null object
math score                     1000 non-null int64
reading score                  1000 non-null int64
writing score                  1000 non-null int64
dtypes: int64(3), object(5)
memory usage: 62.6+ KB

# Exploring Dataset Content
df.head()

	gender	race/ethnicity	parental level of education	lunch	test preparation course	math score	reading score	writing score
0	female	group B	bachelor's degree	standard	None	72	72	74
1	female	group C	some college	standard	Completed	69	90	88
2	female	group B	master's degree	standard	None	90	95	93
3	male	group A	associate's degree	free/reduced	None	47	57	44
4	male	group C	some college	standard	None	76	78	75

df.tail()

	gender	race/ethnicity	parental level of education	lunch	test preparation course	math score	reading score	writing score
995	female	group E	master's degree	standard	completed	88	99	95
996	male	group C	high school	free/reduced	None	62	55	55
997	female	group C	high school	free/reduced	completed	59	71	65
998	female	group D	some college	standard	completed	68	78	77
999	female	group D	some college	free/reduced	None	77	86	86

print('Number of Features In Dataset :', df.shape[1])
print('Number of Instances In Dataset : ', df.shape[0])
Number of Features In Dataset : 8
Number of Instances In Dataset :  1000
# on a pandas DataFrame will provide you with summary statistics for the numerical columns in the DataFrame. 
#This includes statistics like count, mean, standard deviation, minimum, 
#25th percentile ,
#median (50th percentile), 
#75th percentile , and maximum.

df.describe()

	math score	reading score	writing score
count	1000.00000	1000.000000	1000.000000
mean	66.08900	69.169000	68.054000
std	15.16308	14.600192	15.195657
min	0.00000	17.000000	10.000000
25%	57.00000	59.000000	57.750000
50%	66.00000	70.000000	69.000000
75%	77.00000	79.000000	79.000000
max	100.00000	100.000000	100.000000

df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 8 columns):
gender                         1000 non-null object
race/ethnicity                 1000 non-null object
parental level of education    1000 non-null object
lunch                          1000 non-null object
test preparation course        1000 non-null object
math score                     1000 non-null int64
reading score                  1000 non-null int64
writing score                  1000 non-null int64
dtypes: int64(3), object(5)
memory usage: 62.6+ KB
# Checking For Duplicate Rows In Dataset
#duplicated() method to identify duplicate rows and the sum()

print('Number of Duplicated Rows :',df.duplicated().sum())
Number of Duplicated Rows : 0
# Checking For Missing Values In Dataset
# isna() method to create a Boolean DataFrame where True indicates missing values, 
#and then uses sum() to count the number of True values for each column. 

df.isna().sum()
gender                         0
race/ethnicity                 0
parental level of education    0
lunch                          0
test preparation course        0
math score                     0
reading score                  0
writing score                  0
dtype: int64

# 4 Check the number of null value.
null_values=df.isnull().sum()
null_values[null_values>0]
Series([], dtype: int64)
# Calculate the correlation matrix
correlation_matrix = df[['math score', 'reading score', 'writing score']].corr()

# Create a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap')
plt.show()


# 5 Check the dataset and extract the gender (eg. male, female)
gender_df=df[df['gender'].isin(['male','female'])]
gender_df

	gender	race/ethnicity	parental level of education	lunch	test preparation course	math score	reading score	writing score
0	female	group B	bachelor's degree	standard	none	72	72	74
1	female	group C	some college	standard	completed	69	90	88
2	female	group B	master's degree	standard	none	90	95	93
3	male	group A	associate's degree	free/reduced	none	47	57	44
4	male	group C	some college	standard	none	76	78	75
...	...	...	...	...	...	...	...	...
995	female	group E	master's degree	standard	completed	88	99	95
996	male	group C	high school	free/reduced	none	62	55	55
997	female	group C	high school	free/reduced	completed	59	71	65
998	female	group D	some college	standard	completed	68	78	77
999	female	group D	some college	free/reduced	none	77	86	86
1000 rows × 8 columns
# count each gender

gender_count= gender_df['gender'].value_counts()
gender_count
female    518
male      482
Name: gender, dtype: int64
# Assuming you have loaded and processed the student data (assuming 'data' is your DataFrame)

sns.countplot(data=df, x='gender') 
plt.title("Gender Distribution")
plt.xlabel("Gender")
plt.ylabel("Count")
plt.show()
 



# Count the number of students by gender

gender_counts = df['gender'].value_counts()

# Create a pie chart
plt.figure(figsize=(6, 6))
labels = gender_counts.index
sizes = gender_counts.values
colors = ['lightcoral', 'lightskyblue']
explode = (0.1, 0)  # Explode the first slice (Female)

plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)
plt.title('Gender Distribution of Students')
plt.show()
 
# 6 Check for Race/Ethnicity of People and 
# retrieve number of different races/ethnicity of people from the dataset.

df['race/ethnicity'].nunique()
5
df['race/ethnicity'].value_counts()
group C    319
group D    262
group B    190
group E    140
group A     89
Name: race/ethnicity, dtype: int64
#Visualize the race/ethnicity distribution using a bar plot:
# Assuming you have loaded and processed the student data (assuming 'df' is your DataFrame)

plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='race/ethnicity')
plt.title('Race/Ethnicity Distribution')
plt.xlabel('Race/Ethnicity')
plt.ylabel('Count')
plt.show()
 
# 7. Check for Parent’s level of education
df['parental level of education'].unique()
array(["bachelor's degree", 'some college', "master's degree",
       "associate's degree", 'high school', 'some high school'],
      dtype=object)
#Visualize the parent's level of education using a bar plot:

plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='parental level of education', hue='gender')
plt.title("Parent's Level of Education Distribution by Gender")
plt.xticks(rotation=45)
plt.xlabel("Parent's Level of Education")
plt.ylabel('Count')
plt.legend(title='Gender')
plt.show()
 
# 8 Check for different types of lunches.
df['lunch'].unique()
array(['standard', 'free/reduced'], dtype=object)
#Visualize the types of lunch using a pie chart:

plt.figure(figsize=(6, 6))
labels = data['lunch'].value_counts().index
sizes = data['lunch'].value_counts().values
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.title('Types of Lunch')
plt.show() 


# 9.Extract types of test preparation course.
df['test preparation course'].unique()
array(['none', 'completed'], dtype=object)
#Visualize the test preparation course distribution using a bar plot:

plt.figure(figsize=(6, 4))
sns.countplot(data=data, x='test preparation course')
plt.title('Test Preparation Course Distribution')
plt.xlabel('Test Preparation Course')
plt.ylabel('Count')
plt.show()
 
#10. Analyze maximum and minimum scores in maths
max_math_score = df['math score'].max()
min_math_score = df['math score'].min()

print("\nMax and Min Scores in Maths:")
print("Max:", max_math_score)
print("Min:", min_math_score)

Max and Min Scores in Maths:
Max: 100
Min: 0

#11. Analyze maximum and minimum scores in reading
max_reading_score = data['reading score'].max()
min_reading_score = data['reading score'].min()

print("\nMax and Min Scores in Reading:")
print("Max:", max_reading_score)
print("Min:", min_reading_score)

Max and Min Scores in Reading:
Max: 100
Min: 17

# 12. Analyze maximum and minimum scores in writing
max_writing_score = data['writing score'].max()
min_writing_score = data['writing score'].min()

print("\nMax and Min Scores in Writing:")
print("Max:", max_writing_score)
print("Min:", min_writing_score)

Max and Min Scores in Writing:
Max: 100
Min: 10

# 13. Number of students having maximum score in maths
max_math_score_count = (data['math score'] == max_math_score).sum()

print("\nNumber of Students with Maximum Scores:")
print("Math:", max_math_score_count)

Number of Students with Maximum Scores:
Math: 7

#14. Number of students having maximum score in reading
max_reading_score_count = (data['reading score'] == max_reading_score).sum()

print("\nNumber of Students with Maximum Scores:")
print("Reading:", max_reading_score_count)

Number of Students with Maximum Scores:
Reading: 17

# 15.Number of students having maximum score in writing
max_writing_score_count = (data['writing score'] == max_writing_score).sum()
print("\nNumber of Students with Maximum Scores:")
print("Writing:", max_writing_score_count)

Number of Students with Maximum Scores:
Writing: 14

#16. Number of students having maximum marks in all three categories
max_scores_count = ((data['math score'] == max_math_score) & 
                   (data['reading score'] == max_reading_score) & 
                   (data['writing score'] == max_writing_score)).sum()
print("All Three Categories:", max_scores_count)
All Three Categories: 3

#Visualize the number of students with maximum scores in each category:

plt.figure(figsize=(8, 4))

plt.subplot(1, 3, 1)
sns.countplot(data=data[data['math score'] == max_math_score], x='gender')
plt.title('Students with Max Math Score')
plt.xlabel('Gender')
plt.ylabel('Count')

plt.subplot(1, 3, 2)
sns.countplot(data=data[data['reading score'] == max_reading_score], x='gender')
plt.title('Students with Max Reading Score')
plt.xlabel('Gender')
plt.ylabel('Count')

plt.subplot(1, 3, 3)
sns.countplot(data=data[data['writing score'] == max_writing_score], x='gender')
plt.title('Students with Max Writing Score')
plt.xlabel('Gender')
plt.ylabel('Count')

plt.tight_layout()
plt.show()

 

#17. Number of students having minimum marks in all three categories
min_scores_count = ((data['math score'] == min_math_score) & 
                   (data['reading score'] == min_reading_score) & 
                   (data['writing score'] == min_writing_score)).sum()

print("\nNumber of Students with Minimum Scores in All Categories:", min_scores_count)

Number of Students with Minimum Scores in All Categories: 1

#Visualize the number of students with minimum scores in each category:

plt.figure(figsize=(8, 4))

plt.subplot(1, 3, 1)
sns.countplot(data=data[data['math score'] == min_math_score], x='gender')
plt.title('Students with Min Math Score')
plt.xlabel('Gender')
plt.ylabel('Count')

plt.subplot(1, 3, 2)
sns.countplot(data=data[data['reading score'] == min_reading_score], x='gender')
plt.title('Students with Min Reading Score')
plt.xlabel('Gender')
plt.ylabel('Count')

plt.subplot(1, 3, 3)
sns.countplot(data=data[data['writing score'] == min_writing_score], x='gender')
plt.title('Students with Min Writing Score')
plt.xlabel('Gender')
plt.ylabel('Count')

plt.tight_layout()
plt.show()

 

# 18.Marks breakdown according to Gender.
# a. Calculate Max, Min and Average Math Score based on Gender.

gender_math_scores = data.groupby('gender')['math score'].agg(['max', 'min', 'mean'])

print("\nMarks Breakdown by Gender:")
print("\nMath Scores:")
print(gender_math_scores)

Marks Breakdown by Gender:

Math Scores:
        max  min       mean
gender                     
female  100    0  63.633205
male    100   27  68.728216

# b. Calculate Max, Min and Average Reading Score based on Gender.

gender_reading_scores = data.groupby('gender')['reading score'].agg(['max', 'min','mean'])

print("\nMarks Breakdown by Gender:")
print("\nReading Scores:")
print(gender_reading_scores)

Marks Breakdown by Gender:

Reading Scores:
        max  min       mean
gender                     
female  100   17  72.608108
male    100   23  65.473029

# c. Calculate Max, Min and Average Writing Score based on Gender.

gender_writing_scores = data.groupby('gender')['writing score'].agg(['max', 'min', 'mean'])

print("\nMarks Breakdown by Gender:")
print("\nWriting Scores:")
print(gender_writing_scores)

Marks Breakdown by Gender:

Writing Scores:
        max  min       mean
gender                     
female  100   10  72.467181
male    100   15  63.311203

# Box plots for scores by gender

plt.figure(figsize=(12, 5))
plt.subplot(1, 3, 1)
sns.boxplot(data=data, x='gender', y='math score')
plt.title("Math Scores by Gender")
plt.subplot(1, 3, 2)
sns.boxplot(data=data, x='gender', y='reading score')
plt.title("Reading Scores by Gender")
plt.subplot(1, 3, 3)
sns.boxplot(data=data, x='gender', y='writing score')
plt.title("Writing Scores by Gender")
plt.tight_layout()
plt.show()
 


CONCULSION: the work of the data analyst in exploring and analyzing student performance data has provided valuable insights that can inform strategic planning and decision-making within the university. Moving forward, it is essential to continue leveraging data analytics to monitor student progress, identify areas for improvement, and drive continuous enhancement of the B Tech Data Science program.


RESULT:
the results of the data analysis provide a roadmap for the university to enhance the B Tech Data Science program and improve student outcomes. By leveraging these insights, the university can take proactive steps to support student success and ensure that graduates are well-prepared for careers in the field of data science.


